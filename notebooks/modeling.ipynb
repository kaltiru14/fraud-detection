{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb1b3a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report, precision_recall_curve, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "859d1647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fraud Data\n",
    "fraud_X_train = pd.read_csv(\"../data/processed/fraud_X_train.csv\")\n",
    "fraud_X_test  = pd.read_csv(\"../data/processed/fraud_X_test.csv\")\n",
    "fraud_y_train = pd.read_csv(\"../data/processed/fraud_y_train.csv\").values.ravel()\n",
    "fraud_y_test  = pd.read_csv(\"../data/processed/fraud_y_test.csv\").values.ravel()\n",
    "\n",
    "# Credit Card Data\n",
    "credit_X_train = pd.read_csv(\"../data/processed/credit_X_train.csv\")\n",
    "credit_X_test  = pd.read_csv(\"../data/processed/credit_X_test.csv\")\n",
    "credit_y_train = pd.read_csv(\"../data/processed/credit_y_train.csv\").values.ravel()\n",
    "credit_y_test  = pd.read_csv(\"../data/processed/credit_y_test.csv\").values.ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d5ee522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression — FRAUD DATA\n",
      "F1-Score: 0.6705911209222467\n",
      "PR-AUC: 0.5787699929435683\n",
      "Confusion Matrix:\n",
      " [[23120   256]\n",
      " [ 1087  1367]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97     23376\n",
      "           1       0.84      0.56      0.67      2454\n",
      "\n",
      "    accuracy                           0.95     25830\n",
      "   macro avg       0.90      0.77      0.82     25830\n",
      "weighted avg       0.94      0.95      0.94     25830\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. Baseline Model: Logistic Regression\n",
    "# -----------------------------\n",
    "log_reg = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)\n",
    "log_reg.fit(fraud_X_train, fraud_y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_lr = log_reg.predict(fraud_X_test)\n",
    "y_prob_lr = log_reg.predict_proba(fraud_X_test)[:,1]\n",
    "\n",
    "# Metrics\n",
    "f1_lr = f1_score(fraud_y_test, y_pred_lr)\n",
    "cm_lr = confusion_matrix(fraud_y_test, y_pred_lr)\n",
    "precision_lr, recall_lr, _ = precision_recall_curve(fraud_y_test, y_prob_lr)\n",
    "pr_auc_lr = auc(recall_lr, precision_lr)\n",
    "\n",
    "print(\"Logistic Regression — FRAUD DATA\")\n",
    "print(\"F1-Score:\", f1_lr)\n",
    "print(\"PR-AUC:\", pr_auc_lr)\n",
    "print(\"Confusion Matrix:\\n\", cm_lr)\n",
    "print(\"Classification Report:\\n\", classification_report(fraud_y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba98465d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best RF Params: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Random Forest — FRAUD DATA\n",
      "F1-Score: 0.6881937436932392\n",
      "PR-AUC: 0.6429118781361309\n",
      "Confusion Matrix:\n",
      " [[23230   146]\n",
      " [ 1090  1364]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97     23376\n",
      "           1       0.90      0.56      0.69      2454\n",
      "\n",
      "    accuracy                           0.95     25830\n",
      "   macro avg       0.93      0.77      0.83     25830\n",
      "weighted avg       0.95      0.95      0.95     25830\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 15, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "grid_rf = GridSearchCV(rf, param_grid, scoring='f1', cv=5, n_jobs=-1, verbose=1)\n",
    "grid_rf.fit(fraud_X_train, fraud_y_train)\n",
    "\n",
    "best_rf = grid_rf.best_estimator_\n",
    "print(\"Best RF Params:\", grid_rf.best_params_)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rf = best_rf.predict(fraud_X_test)\n",
    "y_prob_rf = best_rf.predict_proba(fraud_X_test)[:,1]\n",
    "\n",
    "precision_rf, recall_rf, _ = precision_recall_curve(fraud_y_test, y_prob_rf)\n",
    "pr_auc_rf = auc(recall_rf, precision_rf)\n",
    "f1_rf = f1_score(fraud_y_test, y_pred_rf)\n",
    "cm_rf = confusion_matrix(fraud_y_test, y_pred_rf)\n",
    "\n",
    "print(\"Random Forest — FRAUD DATA\")\n",
    "print(\"F1-Score:\", f1_rf)\n",
    "print(\"PR-AUC:\", pr_auc_rf)\n",
    "print(\"Confusion Matrix:\\n\", cm_rf)\n",
    "print(classification_report(fraud_y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b9fa616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR CV F1: 0.8551 ± 0.0011\n",
      "RF CV F1: 0.9579 ± 0.0007\n"
     ]
    }
   ],
   "source": [
    "# 4. Cross-Validation (Stratified K-Fold)\n",
    "# -----------------------------\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "lr_cv_f1 = cross_val_score(log_reg, fraud_X_train, fraud_y_train, scoring='f1', cv=skf)\n",
    "rf_cv_f1 = cross_val_score(best_rf, fraud_X_train, fraud_y_train, scoring='f1', cv=skf)\n",
    "\n",
    "print(\"LR CV F1: {:.4f} ± {:.4f}\".format(lr_cv_f1.mean(), lr_cv_f1.std()))\n",
    "print(\"RF CV F1: {:.4f} ± {:.4f}\".format(rf_cv_f1.mean(), rf_cv_f1.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b3a88d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression — CREDIT DATA\n",
      "F1 Score: 0.23275862068965517\n",
      "AUC-PR: 0.7586498457173735\n",
      "Confusion Matrix:\n",
      " [[56131   520]\n",
      " [   14    81]]\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression on Credit Card Data\n",
    "log_reg.fit(credit_X_train, credit_y_train)\n",
    "y_pred = log_reg.predict(credit_X_test)\n",
    "y_prob = log_reg.predict_proba(credit_X_test)[:,1]\n",
    "\n",
    "credit_lr_f1 = f1_score(credit_y_test, y_pred)\n",
    "precision, recall, _ = precision_recall_curve(credit_y_test, y_prob)\n",
    "credit_lr_aucpr = auc(recall, precision)\n",
    "credit_lr_cm = confusion_matrix(credit_y_test, y_pred)\n",
    "\n",
    "print(\"Logistic Regression — CREDIT DATA\")\n",
    "print(\"F1 Score:\", credit_lr_f1)\n",
    "print(\"AUC-PR:\", credit_lr_aucpr)\n",
    "print(\"Confusion Matrix:\\n\", credit_lr_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "634a2a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest — CREDIT DATA\n",
      "F1 Score: 0.6695652173913044\n",
      "AUC-PR: 0.7960997753841067\n",
      "Confusion Matrix:\n",
      " [[56593    58]\n",
      " [   18    77]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest on Credit Card Data\n",
    "rf.fit(credit_X_train, credit_y_train)\n",
    "y_pred = rf.predict(credit_X_test)\n",
    "y_prob = rf.predict_proba(credit_X_test)[:,1]\n",
    "\n",
    "credit_rf_f1 = f1_score(credit_y_test, y_pred)\n",
    "precision, recall, _ = precision_recall_curve(credit_y_test, y_prob)\n",
    "credit_rf_aucpr = auc(recall, precision)\n",
    "credit_rf_cm = confusion_matrix(credit_y_test, y_pred)\n",
    "\n",
    "print(\"Random Forest — CREDIT DATA\")\n",
    "print(\"F1 Score:\", credit_rf_f1)\n",
    "print(\"AUC-PR:\", credit_rf_aucpr)\n",
    "print(\"Confusion Matrix:\\n\", credit_rf_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78fa959a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Features (RF — Fraud Data):\n",
      "                   feature  importance\n",
      "2        time_since_signup    0.263552\n",
      "5            short_account    0.171632\n",
      "1                      age    0.083440\n",
      "0           purchase_value    0.075185\n",
      "9        purchase_velocity    0.074826\n",
      "3              hour_of_day    0.067402\n",
      "4              day_of_week    0.037419\n",
      "187  country_United States    0.027759\n",
      "52           country_China    0.013834\n",
      "11              source_SEO    0.011231\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 5. Feature Importance (Ensemble)\n",
    "# -----------------------------\n",
    "importances = pd.DataFrame({\n",
    "    'feature': fraud_X_train.columns,\n",
    "    'importance': best_rf.feature_importances_\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "print(\"Top 10 Features (RF — Fraud Data):\")\n",
    "print(importances.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16f5da96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Comparison:\n",
      "                    Model        F1    PR-AUC\n",
      "0    Logistic Regression  0.670591  0.578770\n",
      "1  Random Forest (Tuned)  0.688194  0.642912\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 6. Metrics Comparison Table\n",
    "# -----------------------------\n",
    "comparison = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Random Forest (Tuned)'],\n",
    "    'F1': [f1_lr, f1_rf],\n",
    "    'PR-AUC': [pr_auc_lr, pr_auc_rf]\n",
    "})\n",
    "\n",
    "print(\"\\nModel Comparison:\\n\", comparison)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455a4fec",
   "metadata": {},
   "source": [
    "## Credit Card Fraud Detection — Model Training\n",
    "\n",
    "We trained two models on the Credit Card dataset:\n",
    "\n",
    "1. Logistic Regression — interpretable baseline\n",
    "2. Random Forest — ensemble model to capture nonlinear patterns\n",
    "\n",
    "Because fraud datasets are highly imbalanced, we evaluate using F1-score and PR-AUC rather than accuracy. Stratified splits and cross-validation are used to preserve fraud class distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b176c453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression CV F1: 0.9810 ± 0.0004\n"
     ]
    }
   ],
   "source": [
    "# Stratified Cross-Validation\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)\n",
    "\n",
    "lr_cv_f1 = cross_val_score(\n",
    "    log_reg,\n",
    "    credit_X_train,\n",
    "    credit_y_train,\n",
    "    scoring='f1',\n",
    "    cv=skf\n",
    ")\n",
    "\n",
    "print(\"Logistic Regression CV F1: {:.4f} ± {:.4f}\".format(lr_cv_f1.mean(), lr_cv_f1.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1baaa95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression — CREDIT DATA\n",
      "F1 Score: 0.23275862068965517\n",
      "PR-AUC: 0.7586498457173735\n",
      "Confusion Matrix:\n",
      " [[56131   520]\n",
      " [   14    81]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     56651\n",
      "           1       0.13      0.85      0.23        95\n",
      "\n",
      "    accuracy                           0.99     56746\n",
      "   macro avg       0.57      0.92      0.61     56746\n",
      "weighted avg       1.00      0.99      0.99     56746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression Baseline\n",
    "\n",
    "log_reg.fit(credit_X_train, credit_y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_lr = log_reg.predict(credit_X_test)\n",
    "y_prob_lr = log_reg.predict_proba(credit_X_test)[:,1]\n",
    "\n",
    "# Metrics\n",
    "f1_lr = f1_score(credit_y_test, y_pred_lr)\n",
    "precision_lr, recall_lr, _ = precision_recall_curve(credit_y_test, y_prob_lr)\n",
    "aucpr_lr = auc(recall_lr, precision_lr)\n",
    "cm_lr = confusion_matrix(credit_y_test, y_pred_lr)\n",
    "\n",
    "print(\"Logistic Regression — CREDIT DATA\")\n",
    "print(\"F1 Score:\", f1_lr)\n",
    "print(\"PR-AUC:\", aucpr_lr)\n",
    "print(\"Confusion Matrix:\\n\", cm_lr)\n",
    "print(\"Classification Report:\\n\", classification_report(credit_y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10060be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RF Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Tuning for Random Forest\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(\n",
    "    RandomForestClassifier(class_weight='balanced', random_state=42),\n",
    "    param_grid,\n",
    "    scoring='f1',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_rf.fit(credit_X_train, credit_y_train)\n",
    "\n",
    "print(\"Best RF Parameters:\", grid_rf.best_params_)\n",
    "\n",
    "rf = grid_rf.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cdaa66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest — CREDIT DATA\n",
      "F1 Score: 0.8135593220338984\n",
      "PR-AUC: 0.8212551396272318\n",
      "Confusion Matrix:\n",
      " [[56641    10]\n",
      " [   23    72]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56651\n",
      "           1       0.88      0.76      0.81        95\n",
      "\n",
      "    accuracy                           1.00     56746\n",
      "   macro avg       0.94      0.88      0.91     56746\n",
      "weighted avg       1.00      1.00      1.00     56746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest & Evaluate\n",
    "y_pred_rf = rf.predict(credit_X_test)\n",
    "y_prob_rf = rf.predict_proba(credit_X_test)[:,1]\n",
    "\n",
    "f1_rf = f1_score(credit_y_test, y_pred_rf)\n",
    "precision_rf, recall_rf, _ = precision_recall_curve(credit_y_test, y_prob_rf)\n",
    "aucpr_rf = auc(recall_rf, precision_rf)\n",
    "cm_rf = confusion_matrix(credit_y_test, y_pred_rf)\n",
    "\n",
    "print(\"Random Forest — CREDIT DATA\")\n",
    "print(\"F1 Score:\", f1_rf)\n",
    "print(\"PR-AUC:\", aucpr_rf)\n",
    "print(\"Confusion Matrix:\\n\", cm_rf)\n",
    "print(\"Classification Report:\\n\", classification_report(credit_y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d8c09bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>PR-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.232759</td>\n",
       "      <td>0.758650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>0.821255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  F1 Score    PR-AUC\n",
       "0  Logistic Regression  0.232759  0.758650\n",
       "1        Random Forest  0.813559  0.821255"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare Models\n",
    "comparison = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Random Forest'],\n",
    "    'F1 Score': [f1_lr, f1_rf],\n",
    "    'PR-AUC': [aucpr_lr, aucpr_rf]\n",
    "})\n",
    "\n",
    "comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ef92f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>V14</td>\n",
       "      <td>0.234198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>V10</td>\n",
       "      <td>0.156478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>V17</td>\n",
       "      <td>0.111272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>V12</td>\n",
       "      <td>0.090547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V4</td>\n",
       "      <td>0.086420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V3</td>\n",
       "      <td>0.058940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>V11</td>\n",
       "      <td>0.047810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V2</td>\n",
       "      <td>0.047013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>V16</td>\n",
       "      <td>0.029937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>V7</td>\n",
       "      <td>0.023518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature  importance\n",
       "13     V14    0.234198\n",
       "9      V10    0.156478\n",
       "16     V17    0.111272\n",
       "11     V12    0.090547\n",
       "3       V4    0.086420\n",
       "2       V3    0.058940\n",
       "10     V11    0.047810\n",
       "1       V2    0.047013\n",
       "15     V16    0.029937\n",
       "6       V7    0.023518"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Importance\n",
    "importances = pd.DataFrame({\n",
    "    'feature': credit_X_train.columns,\n",
    "    'importance': rf.feature_importances_\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "importances.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef588f06",
   "metadata": {},
   "source": [
    "### Cross-Validation\n",
    "\n",
    "We applied stratified 5-fold cross-validation to ensure each fold preserved the fraud ratio.\n",
    "This provides more reliable estimates than a single train-test split, especially under heavy imbalance.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
